% Template for FPL 2005 papers; to be used with:
%          spconf.sty   - ICASSP/ICIP LaTeX style file
%          IEEEtran.bst - IEEE bibliography style file

% Created:  Apr-May 2005 - Riku Uusikartano -- riku.uusikartano@tut.fi

% --------------------------------------------------------------------------
\documentclass{article}

% The amsmath and epsfig packages greatly simplify the process of adding
% equations and figures to the document, and thus their use is highly
% recommended.
% ------------
\usepackage{spconf,amsmath,epsfig}





% Title.
% ------
\title{PGR : A Software Package for Reconfigurable Super-Computing}




% Author's name.
% --------------
\name{Tsuyoshi~Hamada
\sthanks{This work is supported by the Exploratory Software Project 2004,2005 of Information-Technology Promotion Agency, Japan.}
 and Naohito~Nakasato
\sthanks{Special Postdoctoral Researcher at RIKEN.}
}

\address{
  Computational Astrophysics Laboratory\\
  The institute of physical and chemical research~(RIKEN)\\
  2-1, Hirosawa, Wako, Saitama 351-0198, Japan\\
  email: thamada@riken.jp, nakasato@riken.jp}


% Hyphenation (hyphenate all names and non-english words here).
% -------------------------------------------------------------
\hyphenation{Tam-pe-re micro-soft}




\begin{document}


\maketitle




% Abstract.
% ---------
\begin{abstract}
In this paper, we describe a methodology for implementing FPGA-based
accelerator(FBA) from a high-level specification language.  We have
constructed a software package specially tuned for accelerating
particle-based scientific computations with an FBA.  Our software
generates (a)a suitable configuration for the FPGA, (b) the C source
code for interfacing with the FBA, and (c) a software emulator. The
FPGA configuration is build by combining components from a library of
parametrized arithmetic modules; these modules implement fixed-point,
floating-point and logarithmic number system with flexible bitwidth
and pipeline stages.  To make certain our methodology is effective, we
have applied our methodology to acceleration of astrophysical $N$-body
application with two types of platforms.  One is our PROGRAPE-3 with
four XC2VP70-5 FPGAs and another is a minimum composition of CRAY-XD1
with one XC2VP50-7 FPGA.
As the result, we have achieved peak performance of 324 Gflops with PROGRAPE-3
and 45 Gflops with the minimum CRAY-XD1, sustained performance of 236 Gflops with
PROGRAPE-3 and 34 Gflops with the CRAY-XD1. 
\end{abstract}



% First section, often named as Introduction.
% -------------------------------------------
\section{Introduction}
\label{sec:intro}


Recently, scientific computation using FPGAs begins to be promising
and attract a several group of astrophysicists.
Previously, many works related to scientific computation using FPGAs
have been reported and, roughly speaking, 
those works can be classified into following three subjects;
(A) hardware implementations, (B) construction of arithmetic modules
and (C) programming technique for generating a
computing core for FPGAs. 
In this work, we present results of our current efforts for each of those subjects. 
Specifically, we have constructed a software package specially 
tuned for accelerating scientific computations with FPGA-based systems.
Although we will show details of our methodology in the following sections, 
first we briefly describe each subject as follows.

(A) {\bf Hardware Implementations}:
In the first subject of hardware implementations,
PROGRAPE-1(PROgrammable GRAPE-1)\cite{HFKM00} is
an earliest example of the use of a reconfigurable hardware for
scientific computation.  PROGRAPE-1 is an FPGA-Based Accelerator(FBA)
for astrophysical many-body simulations. It is implemented with two
Altera EPF10K100 FPGAs. Comparing with modern FPGAs, the EPF10K100 is
old-fashioned and has only 100k gates per one chip.
On the PROGRAPE-1 board, they have implemented a computing core
that calculates gravitational force
$\mathbf{a}_i$ of $i$-th particle exerted by all other particles
used in astrophysical many-body simulations:

\begin{equation}
\mathbf{ a}_i = \sum_j {m_j \mathbf{ r}_{ij} \over (r_{ij}^2 + \varepsilon^2)^{3/2}}
\end{equation}

where $\mathbf{r}_{ij} = \mathbf{r}_j - \mathbf{r}_i $ is a relative
vector between $i$ and $j$-th particles, $m_{j}$ is mass of $j$-th
particle, and $\varepsilon$ is a softening parameter that prevents a
zero-division.  They have obtained peak throughput performance of 0.96
Gflops for this calculation.  An essential point of the PROGRAPE-1 is
using fixed-point and short-length logarithmic number formats instead
of the IEEE standard floating-point (FP) format.  In the processor
core of PROGRAPE-1, they have adopted 20-bit fixed-point format
 in a first stage for subtraction, 14-bit logarithmic number
format(7-bit exponent, 5-bit mantissa, sign flag and non-zero flag)
 in inner stages for division and square root etc., and 
56-bit of fixed-point format in a last stage for summation.  That is though available
resource of FPGA systems is limited, FBA systems can be attractive and
competitive if an application does not need high accuracy such as
double precision that is used in general computing with conventional
CPUs.  After the PROGRAPE-1, a several group have reported similar FBA
systems (\cite{LKM02}\cite{SS03}\cite{AKEDC04}).  In all of those
works, they have used HDL as system programming language for
constructing a computing core and mentioned the need of automation the
task of programming.  We will show our answer to such demands in this
paper.  To prove our methodology described in this paper to be
correct, we have developed new FBA board (PROGRAPE-3 board in Figure
\ref{photopg3}) with modern FPGAs as a target hardware.

(B) {\bf Arithmetic Modules}:
In the second subject, a main task is to construct a library
of parametrized arithmetic modules (AM). 
For example, \cite{JL01}\cite{LCCN04} have presented parametrized FP adders and
multipliers, and \cite{LKM02}\cite{WN04} presented parametrized FP square-roots and divisions. 
However, even if these basic AMs are existed, 
it is insufficient to construct a computing core for scientific computations.
In most of those works, square root and divisions are implemented
using subtracters and shifters. 
This approach is not suitable especially in pipelined data-path,
because the carry propagation of ripple-carried subtracter becomes long.
Instead of standard algorithm above, 
using Function Evaluation Units(FEUs), which calculate arbitrary functions using some approximation methods,
is efficient in most cases.
One can use FEUs for calculating arbitrary functions such as
$\sqrt{x}$, ${\rm log}(x)$, ${\rm exp}(x)$ that are commonly appeared in 
scientific computations.
In implementing a FEU, one can have three approximation methods such as
a table look-up method ($0$-th order), a polynomial approximation method ($n$-th order),
or the hybrid method\cite{FO01}\cite{M97}. 
With HDL that is static in its nature except generic parameters
such as \verb|GENERIC| or \verb|ATTRIBUTE|,
implementation of a general FEU that support arbitrary functions, 
different methods, and variable precision is highly difficult task.
To solve this problem, one can construct a software that dynamically generate 
HDL description for a FEU.
The approach of dynamic generation is applicable for generating
not only FEUs but general FP-AMs that is also
better to support variable precisions.
Here in this work, we have constructed such software for our purpose.
At run-time, by selecting a desired functions and an approximation method
(in case of the FEU generation) or desired precision and number format
(in case of the AM generation), our software generate a corresponding module.
Details will be described in Section \ref{sec:PGR}.

(C) {\bf Generation of a Computing Core}:
Even if the FP-AMs are existed as libraries or generated
from a software, one needs a deep understanding of details of such AMs
to construct a computing core for their purpose.
The task in the third subject is to solve the this issue
of generating a computing core using the AMs.
A real concern here is how to convert a scientific application
written in a high-level language such as C, Java or C++ into an FPGA configuration.

PAM-Blox\cite{MMF97} and JHDL\cite{BH98} are first examples
to allow such conversion from C++ and Java, respectively.
The PAM-Blox concentrates on automation and simplicity to explore the design space.
The JHDL treats circuits as objects and but has only a few elemental FP-AMs
so that it seems not to be interested in scientific computations so much.  
In both work, authors have emphasized the importance of automatic
generation of APIs that is needed to communicate between FBAs and a host processor.
In general, an software between the FBA and the host processor
should be implemented to maximize data transfer rate and minimize latency.
Even if a smart tool can generates an FPGA configuration of a computing core,
one can't necessarily write such high performance communication software.

As well as communication software, 
the performance of a particular application
is very sensitive to detailed {\it architecture} of a computing core.
Here, we consider a computing core consists of inner and outer core.
Specifically, in astrophysical many-body simulations,
one can think an inner core is a calculation unit of gravitational force between two particles
shown in eq. (1) and an outer core is a memory unit that feeds data of two particles 
to the inner core and fetch results from the inner core. 
An obvious implantation of such core is that the outer core
feeds position and mass of $i-$th and $j-$th particles, and
and fetch partial force in each step of the summation.
This implementation is most flexible but worst efficient in terms of data transfer.
In the PROGRAPE-1 (and other family of GRAPE\cite{MT98}),
the computing core is implemented such that
(a) data of $i-$th particle is stored inside the inner core
(b) the inner core accumulate partial sums inside
and (c) the outer core feeds $j-$th data continuously and 
fetch only the accumulated force $a_{i}$.
Clearly, even with a same inner core, performance 
can change drastically depending on detailed {\it memory architecture} of an outer core.

In the PAM-Blox\cite{MMF97}, authors have introduced an important concept
of {\it domain specific compiler} \cite{MPMF01}. 
In such domain specific compiler, a promising application is limited by the
compiler. The point is that there is no almighty architecture for any problem.
Specifying the application domain produces good results for
the tool developer and the tool users.  For the tool developer, the
language specification becomes compact so it can be easy to implement
a compiler that specializes to an application domain if once the
module generator has been completed as a core component of a
programming tool.  For the tool users, it becomes clear whether the
tool agrees with a purpose and easy to understand such a compact
language specification.
Because PAM-Blox seems very wonderful tool, we feel they might appeal
more positively and very regrettable not to try to accelerate 
scientific computations such as gravitational many-body simulations.

For domains within scientific many-body simulations, we have developed
PGR(Processors Generator for Reconfigurable system) package.  Our
purpose is to put the FBA design working under {\it user}'s control.
Here, we consider scientists in physics, astrophysics, chemistry or bioscience as
the target {\it user}. Our methodology doesn't target specialists in
electronics.  In contrast, previous design methodologies seem to
concentrate on hardware developers.  Our methodology realizes
following requirements that is not sufficiently satisfied by the
previous works.

\begin{itemize}
\item[(1)] Target user only has to write a description as short as
possible to realize user's requirements.
\item[(2)] All of the hardware configurations, software emulator,
communication libraries are generated by some clever tool.
\item[(3)] At least one or more hardware platforms are actually available.
\item[(4)] The absolutely high performance is shown on a hardware platform.
\end{itemize}

The remainder of this paper is organized as follows.  Section 2 gives
an overview of our methodology.  In section 3, we show implementation
results for astrophysical $N$-body simulations using PGR package.
Section 4 is devoted to comparison to relevant works.  Finally we
conclude this paper in section 5.


% Second section.
% ---------------
\section{PGR : Processors Generator for Reconfigurable systems}
\label{sec:PGR}

\subsection{Design flow in PGR}

Figure \ref{PGRFLOW} shows a schematic outline of design flow of PGR package.
As a first step, a user must write a source code for the user's application
in PGR Description Languages(PGDL; described in Section \ref{SecPGDL}).
Specifically, the PGDL source code define dataflow for the application
and variable names used for generating interface library to a FBA.
Inside PGR package, four components (parser, module generator, dataflow
generator and compiler)
are doing real jobs as following way;
\begin{itemize}
\item[stage 1] the parser analyzes the PGDL source code and outputs results
as an internal expressions used in the following stages.
\item[stage 2] the module generator convert arithmetic modules definitions
into VHDL source codes and source codes of software emulator for each
arithmetic modules.
\item[stage 3] the dataflow generator compute the dataflow graph
while it inserts delay register between modules.
\item[stage 4] the compiler generates final outputs such as
top-level VHDL code, VHDL library code for arithmetic modules,
and source code of the library interface and software emulator.
\end{itemize}
Note that the software emulator and the interface library
source codes are written in C and both have a special top-level function
with exactly same arguments each other.
Namely, one can easily switch between software emulation
and real runs on the FBA by liking one of both source code.
After the user satisfied with emulation results, the user finally synthesize
the VHDL code using a CAD software and setup a FBA using the obtained
configuration.
Then, the user can test performance of the processors running on the FBA.


%%The design flow is simple in PGR package.
%%Figure\ref{PGRFLOW} shows the outlined design flow of PGR package.
%%First of all, a user writes a
%%description code using PGR Description Language (PGDL; described in
%%Section \ref{SecPGDL}) which defines the dataflow in an FBA.  The user
%%gives the PGDL file to PGR package, then PGR package generates 1)
%%hardware descriptions such as HDL files, CAD project files etc, 2) a
%%bit-level software emulator in C, 3) a API library.  Then, the user
%%connects the software emulator to their already written simulation
%%code through the APIs and verify their design in bit-level.  After,
%%user sets up the FBA using generated hardware specifications.  The
%%form of API for the FBA is quite same as that for the software
%%emulator, so the user can execute own application only by changing the
%%API object files to handle the FBA. No correction is necessary for user.

\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/designflow.eps,width=84mm}}
\end{minipage}
\caption{Design flow of PGR package}\label{PGRFLOW}
\end{figure}





\subsection{PgModules : PGR Parametrized Arithmetic Modules}

PgModules(PGR parametrized arithmetic modules) implement fixed-point, 
FP and logarithmic number system (LNS) AMs and 
are the most low-level components for PGR package.
These modules include addition, subtraction, multiplication, division, and square-root, etc. 
Currently, PGR package supports
29 parametrized AMs as shown in table \ref{tabpgmod}.


In this table, modules with {\tt pg\_float} correspond to FP arithmetics. 
We define internal floating-point format with 1-bit
for a sign flag, 1-bit for a non-zero expression, $m$-bit for
exponent, and $n$-bit for mantissa, here after we  will use FP$_{m+n+2}$(m,n) as the notation for this format
\footnote{LNS$_{m+n+2}$(m,n) is notation for the logarithmic format
 with 1-bit sign, 1-bit nonzero, $m$-bit exponent and $n$-bit
 mantissa.  FIX$_{n}$ is notation for the signed fixed-point format
 with $n$-bit.}.  The $m$ and $n$ can be changed arbitrary up to
 FP$_{33}$(8, 23) which corresponds to the IEEE single precision.

For example, in the PGDL, we can generate an FP$_{26}$(8,16) addition module
as follows;
\begin{verbatim}
pg_float_add(x,y,z,26,16,1);
\end{verbatim}
This example calculates $z = x + y$. 
Here, the arguments \verb|x| and \verb|y| are the inputs, the output is \verb|z|.
And \verb|26| and \verb|16| express total and mantissa bitwidth of FP$_{26}$(8,16)


And the last, \verb|1| specifies the number of pipeline stages of this module.
Note that for the rounding operation, we have implemented nine types
of several options that also can be changed by a hidden argument in the PGDL.
If this argument is omitted like above example, a rounding to the nearest even is selected.



\begin{table}[t]
\caption{List of PgModules}\label{tabpgmod}
\begin{minipage}[b]{1.0\linewidth}\centering
\renewcommand{\arraystretch}{1.2}
\begin{center}
{\scriptsize
\begin{tabular}{ll}

	floating-point format & \\
	    {\tt pg\_float\_add}           &  $+$\\
	    {\tt pg\_float\_unsigned\_add} &  $+$\\
	    {\tt pg\_float\_sub}           &  $-$\\
	    {\tt pg\_float\_unsigned\_sub} &  $-$\\
	    {\tt pg\_float\_mult}          &  $\times$\\
	    {\tt pg\_float\_div}           &  $/$ \\
	    {\tt pg\_float\_sqrt}          &  $\sqrt{x}$ \\
	    {\tt pg\_float\_square}        &  $x^2$\\
	    {\tt pg\_float\_recipro}       &  $x^{-1}$\\
	    {\tt pg\_float\_expadd}        &  $x \cdot 2^{\pm N}$\\
	    {\tt pg\_float\_negate}        &  $-x$\\
	    {\tt pg\_float\_compare}       &  $==$\\
	    {\tt pg\_float\_compare\_abs}  &  $==$\\
	    {\tt pg\_float\_compz}         &  $>0$\\
	    {\tt pg\_float\_compz\_abs}    &  $>0$\\
	    {\tt pg\_float\_accum}         &  $+=$\\
	    {\tt pg\_float\_unsigned\_accum}& $+=$\\
	    {\tt pg\_float\_fixaccum}      &  $+=$\\
	\hline
	fixed-point format & \\
	{\tt pg\_fix\_addsub}          &  $+$, $-$\\
	{\tt pg\_fix\_mult}            &  $\times$\\
	{\tt pg\_fix\_unsigned\_mult}  &  $\times$ (unsigned)\\
	{\tt pg\_fix\_accum}           &  accumulate\\
	\hline
	LNS format& \\
	{\tt pg\_log\_add}             &  $+$\\
	{\tt pg\_log\_unsigned\_add}   &  $+$ (unsigned)\\
	{\tt pg\_log\_muldiv}          &  $\times$, $/$\\
	{\tt pg\_log\_shift}           &  $\sqrt{x}$, $x^2$\\
        {\tt pg\_log\_expadd}          &  $x \cdot 2^{\pm N}$\\
	\hline
	format conversion & \\
	{\tt pg\_conv\_fixtofloat}     &  fix $\Rightarrow$ float\\
	{\tt pg\_conv\_floattofix}     &  float $\Rightarrow$ fix\\
	{\tt pg\_conv\_ftol}           &  fix $\Rightarrow$ log\\
	{\tt pg\_conv\_ltof}           &  log $\Rightarrow$ fix\\
	\hline
\end{tabular}
}
\end{center}
\end{minipage}
\end{table}

Modules {\tt pg\_fix\_addsub} and {\tt pg\_fix\_accum} are FIX
adder/subtracter and accumulator, respectively.  Moreover, modules {\tt
pg\_log\_muldiv} and {\tt pg\_log\_add} are LNS multiplier/divider and
adder, respectively.

In the format of LNS, a positive,
non-zero real number $x$ is represented by its base-2 logarithm $y$ as
$x=2^{y}$.
The LNS is useful because operation such as multiplication and square root
are easier to implement than in the usual FP format.
For more details of the LNS, see GRAPE-5 paper\cite{KFMT00}.

In tables \ref{tabpg_float_sqrt}, \ref{tabpg_log_unsigned_add}, we show
resource consumption and clock frequency of FP square root and LNS unsigned add AMs.
Despite we have implemented all of the parametrized AMs
from full scratch, the obtained performance results
are almost same as other implementations such as \cite{LKM02}.



\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/synthe/logadd/Graph/slice.eps,width=84mm}}
\end{minipage}
\caption{TABLE vs TABLE+POLY}\label{LADD_SLICE}
\end{figure}


\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/5model.eps, width=84mm}}
\end{minipage}
\caption{PGR five layers model.}\label{fig5model}
\end{figure}


In some relevant works,
Ho et.al.\cite{THYL04} has used Symmetric Table Addition Method(STAM)\cite{SS99} for their FEUs.
In the STAM, the multiplications for polynomial are replaced by adders and tables. This method is  
suitable for old-fashioned FPGAs which have no embedded multiplier.
On the other hand, in PgModules we use the first order or second order Chebyshev polynomial
to take advantages of embedded multipliers.

To show effectiveness of our approach, figure \ref{LADD_SLICE} shows
the resources consumption as a function of mantissa bitwidth of LNS
unsigned adder mapped on the Xilinx XC2VP FPGA.  In this figure,
``TABLE'' and ``TABLE+POLY'' show results using only look-up table and sectional polynomial approximation with look-up tables, respectively.
The merit of ``TABLE+POLY'' is that we can reduce address bitwidth for look-up table, 
in compensation for extra additions and multiplications.
It is found that the tradeoff point exists at 5-bit in the case of our LNS unsigned adder.


%% The resource consumptions for ``TABLE'' and ``TABLE+POLY'' method can be modeled like following equations:
%% \begin{equation}
%% V_{T}     = {W_{d}} 2^{W_{a}},
%% \label{eq:1}
%% \end{equation}
%% \begin{equation}
%% V_{P}     = \frac{\beta}{\gamma} W_{a} (W_{d}+1) 2^{\gamma}, 
%% \label{eq:2}
%% \end{equation}
%% where $V_{T}$ and $V_{P}$ represent resource consumptions of look-up
%% tables for ``TABLE'' and ``TABLE+POLY'',respectively.  $L_a$ and $L_d$
%% are the bitwidth of address and data of look-up tables, $\alpha,
%% \beta$ and $\gamma$ are coefficients for each functions to be
%% approximated. In ``TABLE'' method, bitwidth of address $W_{a}$ causes
%% exponential increase of $V_{T}$.  In contrast of $V_{T}$, 
%% we can reduce the address bitwidth for look-up tables from $W_{a}$ to
%% $\gamma$, which can be adjusted to reduce $V_{P}$, so that $V_{P}$ can grow up linearly.


%% At the point of 5-bit, the two lines are crossed so one can explore tradeoffs in each design.

%%--------------------------------------------------------------------------------


\begin{table}[t]
\caption{FP Square Root}\label{tabpg_float_sqrt}
\begin{minipage}[b]{1.0\linewidth}\centering
\renewcommand{\arraystretch}{1.2}
\begin{center}
\begin{tabular}{r|r|r|r|r}

\begin{tabular}{c} exp.   \end{tabular} &
\begin{tabular}{c} mant.  \end{tabular} &
\begin{tabular}{c} stages \end{tabular} &
\begin{tabular}{c} MHz    \end{tabular} &
\begin{tabular}{c} slices \end{tabular} \\

\hline\hline
	  8   &  8 & 5 & 215.517 & 86 \\
	      &    & 4 & 157.754 & 71 \\
	      &    & 1 &  79.971 & 51 \\
\hline
	  8   & 16 & 5 & 188.964 & 140 \\
	      &    & 3 & 127.959 & 116 \\
	      &    & 1 &  56.500 &  84 \\
\hline
	  8   & 23 & 5 & 141.243 & 425 \\
	      &    & 3 & 104.998 & 392 \\
	      &    & 1 &  70.210 & 374 \\
\hline
\end{tabular}
\end{center}
\end{minipage}
\end{table}


\begin{table}[t]
\caption{LNS Unsigned Adder}\label{tabpg_log_unsigned_add}
\begin{minipage}[b]{1.0\linewidth}\centering
\renewcommand{\arraystretch}{1.2}
\begin{center}
\begin{tabular}{r|r|r|r|r}

\begin{tabular}{c} exp.   \end{tabular} &
\begin{tabular}{c} mant.  \end{tabular} &
\begin{tabular}{c} stages \end{tabular} &
\begin{tabular}{c} MHz    \end{tabular} &
\begin{tabular}{c} slices \end{tabular} \\

\hline\hline
	  7   &  ~5 & 5 & 201.077 & 94 \\
	      &           & 3 & 151.207 & 72 \\
	      &           & 1 &  64.545 & 57 \\
\hline
	  7   &  ~8 & 6 & 195.369 & 116 \\
	      &                & 4 & 156.961 & 100 \\
	      &                & 1 &  58.828 &  86 \\
\hline
	  20   & 11 & 7 & 218.293 & 191 \\
	       &                & 4 & 148.721 & 125 \\
	       &                & 1 &  53.562 & 115 \\
\hline
\end{tabular}
\end{center}
\end{minipage}
\end{table}


\subsection{PGR five layers model}

To make PGR software independent on a specific hardware,
we create PGR five layers model which divide 
an FBA into five parts.
Figure \ref{fig5model} shows PGR five layers model, 
and it's composed of User Program Layer(UPL), API Layer(APL),
Device Driver Layer(DDL), I/O \& Control Logic Layer(ICL) and
Arithmetic Logic Layer(ALL).

The UPL is a user application which communicates with an FBA through the APL.
The APL contains the top level API implementations that
doesn't depend on an individual FBA.
The DDL consists of both a low level communication library and a device driver software. 
The ICL is a glue logic such as the PCI interface logic and 
local I/O logic on an FBA.
The ALL corresponds to a {\it computing core} explained in Section 1
and is composed of AMs and control logics.


\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/PROGRAPE-3.eps,width=84mm}}
\end{minipage}
\caption{PROGRAPE-3 prototype system: Four Xilinx XC2VP70 FPGA devices are mounted on single board. We use Opteron 2.4GHz machines as host computers and the PCI64 interface between the host and PROGRAPE-3 board.}\label{photopg3}
\end{figure}



\subsection{PGDL: PGR Description Language}
\label{SecPGDL}
In this subsection, we illustrate how pipeline processors(or computing cores)
are described in the PGDL and how such description is converted 
into HDL sources for pipelined processors.

With the current version of PGR package, 
it is specially tuned to generate pipelined processors
for particle-based simulations as explained already.
It is expressed as the following summation form:

\begin{equation}
f_i = \sum_{j = 1}^{n} F(\boldmath{p}_i, \boldmath{p}_j),
\end{equation}

where $f_i$ is summation for $i$-th data, $\boldmath{p}_i$ are
some values associated with $i$-th data, and
$F$ expresses calculations where $i$-th and $j$-th data are as inputs.

As an example target, we consider the following artificial calculations;
%$f_i = \sum_j^n {a_i a_j}.\mbox{(i=1,...,n)}$

\begin{equation}
f_i = \sum_j^n {a_i a_j}.\qquad (i=1,...,n)
\end{equation}

Figure \ref{fig4} shows the block diagram for this example.
Here, $a_i$ and $a_j$ are scalar values for $i$-th and
$j$-th elements, respectively.
This target simply calculates a product of $a_i$ and $a_j$, 
and sums the product up for all $j$.

Figure \ref{fig5} shows the PGDL description of this target function.
In this example, one already sees essential ingredients of an FBA:
data, their representation, functional form of arithmetic operations
between data $i$ and $j$.
The lines \verb|1| and \verb|2| define the bit-length as FP$_{26}$(8,16).
These definitions are actually used in the next block
(lines \verb|3|, \verb|4| and \verb|5| starting with ``/''),
which defines the layout of registers and memory unit.
For the data $a_i$ (and $a_j$), we use FP$_{26}$(8,16) format.
The line ``/NPIPE'' specifies a number pipeline processors (10 processors in this case).
The final part describes the target function itself using
parametrized AMs. It has C-like appearance, but
actually defines the hardware modules and their interconnection.

From such PGDL description, the following ALL (as shown in figure \ref{fig4})
is generated; the $i$-th data is stored in the on-chip memory,
and new data ($j$-th data) is supplied at each clock cycle.
The $i$-th data is unchanged during one calculation, and 
the result ($f_i$) is stored in the register.


\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/simple.eps,width=84mm}}
\end{minipage}
\caption{Block diagram of the example processors(PEs).}\label{fig4}
\end{figure}

\begin{figure}[t]
\scriptsize
\begin{verbatim}
1 #define NFLO 26
2 #define NMAN 16
3 /JPSET x,  aj[], float, NFLO, NMAN;
4 /IPSET y,  ai[], float, NFLO, NMAN;
5 /FOSET z,  fi[], float, NFLO, NMAN;
6 /NPIPE 10;
7 pg_float_mult  (x,   y,  xy, NFLO, NMAN, 1);
8 pg_float_accum (xy,  z,      NFLO, NMAN, 1);
\end{verbatim}
\caption{An example of design entry file written in PGDL}
\label{fig5}
\end{figure}

\section{Application}
\label{sec:Appli}

To show the possibility of PGR package, we have implemented gravitational
force (as shown in eq. (1)) pipeline for astrophysical many-body simulations
Figure \ref{figgravfloat_pgdl} and \ref{figgrav5_pgdl}
show PGDL descriptions for this gravitational force pipeline
using FP$_{26}$(8,16) operations and LNS$_{17}$(7,8) operations, respectively.
Note there are a several differences between two descriptions.
We check accuracy and resource consumption of the different implementations 
to test whether PGR package generates effective implementations.
In Figure \ref{SrError}, we present relative error($=\frac{|\vec{f_{\rm host}}-\vec{f_{\rm fba}}|}{|\vec{f_{\rm host}}|}$, where $\vec{f_{\rm host}}$ is the double precision result, $\vec{f_{\rm fba}}$ is the result by FBA) of our implementations.
And Figure \ref{AreaComp} shows their resource consumptions.

\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/SrGraph.eps,width=84mm}}
\end{minipage}
\caption{Pair-wise relative error for gravitational force calculation in the N-body problem.}\label{SrError}
\end{figure}

\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/synthe/pipe/Graph.eps,width=84mm}}
\end{minipage}
\caption{Area comparison of gravitational N-body implementations.}\label{AreaComp}
\end{figure}

Figure \ref{fig_grav_float_delay} shows a data flow graph that corresponds to the FP pipeline.
PGR package automatically inserts delay register, which are indicated by bold circles,
for synchronizing each operation.

All of our implementations have been correctly working at 133.3MHz on
PROGRAPE-3 and 120 MHz on CRAY-XD1{\footnote{For PROGRAPE-3, we use
Synplify Pro for a backend tool of PGR package. For CRAY-XD1, the
backend tool is Xilinx ISE6.3i.}.  Here, {\it correctly working} means
that gravity force calculated by both of PROGRAPE-3 and CRAY-XD1 for
$16384$ particles is exactly same with results obtained by software
emulator.  In table \ref{tabcompg5}, we compare two implementations of
FP$_{26}$(8,16) and LNS$_{17}$(7,8) with the GRAPE-5
system\cite{KFMT00}; actually, the LNS$_{17}$(7,8) pipeline is
actually equivalent to the GRAPE-5.  The peak performance of
PROGRAPE-3 is 324.2 Gflops and 45.6 Gflops for the minimum composition of CRAY-XD1
\footnote{The result of CRAY-XD1 is just preliminary.}.

Here, the number of floating-point operations per one interaction is 38\cite{MT98}.
The peak performance of the LNS pipelines on single PROGRAPE-3
board is five times faster than single GRAPE-5 board.
And even if we use twice accuracy (i.e., the FP$_{26}$(8,16) pipelines),
the performance is the still two times better than single GRAPE-5.


\begin{table*}[t]
\caption{Implementation result and comparison with other implementation}\label{tabcompg5}
\begin{minipage}[b]{1.0\linewidth}\centering
\renewcommand{\arraystretch}{1.2}
\begin{center}
\begin{tabular}{l|c|c|c|c}
 &
\begin{tabular}{c} GRAPE-5  \end{tabular} &
\multicolumn{2}{|c|} {PROGRAPE-3} &
\begin{tabular}{c} CRAY-XD1 \end{tabular} \\

\hline\hline
Device               &   ASIC             & \multicolumn{2}{|c|}{FPGA(XC2VP70-5)}        & FPGA(XC2VP50-7) \\
Device technology      & 0.5 $\mu m$        & \multicolumn{2}{|c|}{ 0.13 $\mu m$}          & 0.13$\mu m$       \\
Chips/board          &   8                & \multicolumn{2}{|c|}{ 4 }                    & 1  \\
Format :input        & FIX$_{32}$         & FIX$_{32}$       & FP$_{26}$(8,16)           & FIX$_{32}$        \\
Format :internal     & LNS$_{17}$(7,8)    & LNS$_{17}$(7,8)  & FP$_{26}$(8,16)           & LNS$_{17}$(7,8)   \\
Format :accumulation & FIX$_{64}$         & FIX$_{64}$       & FIX$_{64}$                & FIX$_{64}$   \\
Pair-wise error             & 10$^{-2.4}$ &  10$^{-2.4}$     & 10$^{-4.8}$               &  10$^{-2.4}$ \\
PEs/chip             & 2                  &  16              &   6                       & 10           \\
Frequency (MHz)      & 80                 & 133              &  133                      & 120          \\
Peak Gflops/board    & 48.6               & 324.2            & 121.6                     & 45.6         \\
\hline
\end{tabular}
\end{center}
\end{minipage}
\end{table*}




Finally, figure \ref{MEASURE-PERFORM} shows the sustained performance of
single PROGRAPE-3 board and minimum composition of CRAY-XD1 with the LNS implementation as a function of
number of particles $N$. Here, we show the results for the
direct-summation algorithm.  Because the calculation cost
and data transfer cost scale $\propto N^2$ and $N$ respectively, the
sustained performance gradually approaches the peak throughput as the
number of particles increases.

\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
\scriptsize
{\tiny
\begin{verbatim}
 1 /* ------------------------------------------- MACRO */
 2 #define NFLO  26
 3 #define NMAN  16
 4 #define NFIX  57
 5 #define NACC  64
 6 #define NEXAD 39
 7 #define FSCALE (pow(2.0,NEXAD))
 8 /* ---------------------------------- API DEFINITION */
 9 /JPSET xj[3], x[][],  float (NFLO, NMAN);
10 /JPSET mj,    m[],    float (NFLO, NMAN);
11 /IPSET xi[3], x[][],  float (NFLO, NMAN);
12 /IPSET e2,    eps2,   float (NFLO, NMAN);
13 /FOSET sx[3], a[][],  fix   (NACC);
14 /CONST_FLOAT  fshif,  FSCALE, NFLO,NMAN;
15 /SCALE sx : -1.0/(FSCALE);
16 /NPIPE 6;
17 /* ---------------------------------------- PIPELINE */
18 pg_float_sub(xi,xj,dx,    NFLO,NMAN,              4);
19 pg_float_mult(dx,dx, x2,  NFLO,NMAN,              2);
20 pg_float_unsigned_add(x2[0],x2[1],xy, NFLO,NMAN,  4);
21 pg_float_unsigned_add(x2[2],e2,ze,    NFLO,NMAN,  4);
22 pg_float_unsigned_add(xy,ze,r2,       NFLO,NMAN,  4);
23 pg_float_sqrt(r2,r1,      NFLO,NMAN,              3);
24 pg_float_mult(r2,r1,r3,   NFLO,NMAN,              2);
25 pg_float_recipro(r3,r3i,  NFLO,NMAN,              2);
26 pg_float_mult(r3i,mj,mf,  NFLO,NMAN,              2);
27 pg_float_expadd(mf,mfo,   NEXAD,NFLO,NMAN,        1);
28 pg_float_mult(mfo,dx,fx,  NFLO,NMAN,              2);
29 pg_float_fixaccum(fx,sx,  NFLO,NMAN,NFIX,NACC,    4);
\end{verbatim}
}
\end{minipage}
\caption{a PGDL for gravitational force calculation (using 26-bit FP arithmetics)}\label{figgravfloat_pgdl}
\end{figure}




\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
\scriptsize
{\tiny
\begin{verbatim}
 1 /* -------------------------------------------- MACRO */
 2 #define NPOS 32
 3 #define NLOG 17
 4 #define NMAN 8
 5 #define NCUT 6
 6 #define NFOR 57
 7 #define NACC 64
 8 #define NEXAD -31
 9 #define fshift pow(2.0,-1.0*(double)NEXAD)
10 /* ------------------------------------ API DEFINITION */
11 /JPSET xj[3], x[][], fix,       FIX (NPOS);
12 /JPSET mj,    m[],   log,       LNS (NLOG,NMAN);
13 /IPSET xi[3], x[][], ufix,      FIX (NOPS);
14 /IPSET ieps2, eps2,  log,       LNS (NLOG, NMAN);
15 /FOSET sx[3], a[][], fix,       FIX (NACC);
16 /SCALE mj : pow(2.0,95.38);
16 /SCALE sx : -(fshift)/(mj);
17 /NPIPE 16;
18 /* ------------------------------------------ PIPELINE */
19 pg_fix_addsub(SUB,xi,xj,xij,           NPOS,            1);
20 pg_conv_ftol(xij,dx,                   NPOS,NLOG,NMAN,  2);
21 pg_log_shift(1,dx,x2,                  NLOG);
22 pg_log_unsigned_add_itp(x2[0],x2[1], x2y2,   NLOG,NMAN, 4,NCUT);
23 pg_log_unsigned_add_itp(x2[2],ieps2, z2e2,   NLOG,NMAN, 4,NCUT);
24 pg_log_unsigned_add_itp(x2y2,z2e2,   r2,     NLOG,NMAN, 4,NCUT);
25 pg_log_shift(-1,r2,       r1,          NLOG);
26 pg_log_muldiv(MUL,r2,r1,  r3,          NLOG,            1);
27 pg_log_muldiv(SDIV,mj,r3,  mf,         NLOG,            1);
28 pg_log_muldiv(MUL,mf,dx,  fx,          NLOG,            1);
29 pg_log_expadd(fx,fxs,                  NEXAD,NLOG,NMAN, 1);
30 pg_conv_ltof(fxs,  ffx,                NLOG,NMAN,NFOR,  2);
31 pg_fix_accum(ffx,  sx,                 NFOR,NACC,       1);
\end{verbatim}
}
\end{minipage}
\caption{a PGDL for gravitational force calculation (using 17-bit LNS)}\label{figgrav5_pgdl}
\end{figure}



\section{Comparison to relevant works}
In scientific computations on FBAs,
type conversions and scaling operations are confusing and
designing APIs becomes troublesome inevitably.

We note that a similar package to PGR has been reported in
\cite{THYL04}.  The CAST(Computer Arithmetic Synthesis Tool) is a tool
for implementing astrophysical many-body simulations.  We concern that
the CAST seems not to meet the requirements (2,4,5,6) in our introduction.
On the other hand, using PGR package, possible users, 
who want to accelerate their particle simulations with an FBA,
can concentrate on only writing a PGDL code.
That is PGR package can drastically reduce the amount of work for such user.


\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/grav_float_delay.eps,width=84mm}}
\end{minipage}
\caption{Data flow of the gravitational force pipeline. The bold circles are delay registers which are automatically inserted by PGR package.
}\label{fig_grav_float_delay}
\end{figure}

\begin{figure}[t]
\begin{minipage}[b]{1.0\linewidth}\centering
  \centerline{\epsfig{figure=./mat/perform/graph.eps,width=84mm}}
\end{minipage}
\caption{The sustained calculation speed of single PROGRAPE-3 board in Gflops for the direct-summation algorithm, plotted as functions of the number of particles, N.}\label{MEASURE-PERFORM}
\end{figure}



\section{Conclusion}
We have developed PGR package, a software which automatically generate
communication software and the hardware descriptions (the hardware
design of pipeline processors) for FBAs from a high-level description
PGDL.  Using PGR package, we have implemented gravitational force
pipelines used in astrophysical many-body simulations.  The PGDL
description for the gravitational force pipelines is only a several
tens of lines of a text file.  Regardless of a very simple
description, the gravitational force pipelines are implemented
successfully and the obtained performance reaches 236 Gflops on our
hardware PROGRAPE-3 and 34 Gflops on minimum composition of CRAY-XD1.

We specially acknowledge Jun Yatabe, Ryuichi Sudo and others at 
CRAY Japan for our access to CRAY-XD1 and technical helps.

\small

% IEEEtran is a LaTeX style file defining the reference formatting.
% -----------------------------------------------------------------
\bibliographystyle{IEEEtran}

% IEEEabrv is a LaTeX style file defining the abbreviations of different
% journals and conferences. fpl_refs contains the actual reference data
% from which the references are selected into the paper using \cite{}.
% ----------------------------------------------------------------------
\bibliography{IEEEabrv,fpl_refs}




\end{document}
